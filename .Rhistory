-state)
my_data2 <- gather(my_data,
key = "arrest_attribute",
value = "arrest_estimate",
Murder, Assault)
my_data2
my_data2 <- gather(my_data,
key = "arrest_attribute",
value = "arrest_estimate",
-state)
my_data2
my_data <- USArrests[c(1, 10, 20, 30), ]
my_data
my_data <- cbind(state = rownames(my_data), my_data)
my_data
my_data2 <- gather(my_data,
key = "arrest_attribute",
value = "arrest_estimate",
Murder, Assault)
my_data2
my_data2 <- gather(my_data,
key = "arrest_attribute",
value = "arrest_estimate",
Murder:UrbanPop)
my_data2
1
1
1
my_data <- USArrests[c(1, 10, 20, 30), ]
my_data
my_data <- cbind(state = rownames(my_data), my_data)
my_data
my_data2 <- gather(my_data,
key = "arrest_attribute",
value = "arrest_estimate",
Murder:UrbanPop)
my_data2
my_data3 <- spread(my_data2,
key = "arrest_attribute",
value = "arrest_estimate")
my_data3
my_data4 <- unite(my_data,
col = "Murder_Assault",
Murder, Assault,
sep = "_")
my_data4
my_data
my_data2 <- gather(my_data,
key = "arrest_attribute",
value = "arrest_estimate",
Murder:UrbanPop)
my_data2
library(showtext)
showtext_auto()
font_add(family = "cat", regular = "fonts/HoonWhitecatR.ttf")
font_add(family = "dog", regular = "fonts/THEdog.ttf")
font_add(family = "maple", regular = "fonts/MaplestoryBold.ttf")
install.packages("proxy") # 유사도 분석
install.packages("tm") # 텍스트 마이닝 지원 패키지
install.packages("qgraph") # 네트워크 그래프
install.packages("SnowballC") # 어근 추출
library(proxy)
library(tm)
library(qgraph)
library(SnowballC)
m1=matrix(1:4,2)
m1
m1 %*% m1
m2=matrix(1:6,2)
m2
m3=matrix(1:9,3)
m3
m2 %*% m3
lunch <- c("커피 파스타 치킨 샐러드 아이스크림",
"커피 우동 소고기김밥 귤",
"참치김밥 커피 오뎅",
"샐러드 피자 파스타 콜라",
"티라무슈 햄버거 콜라",
"파스타 샐러드 커피"
)
lunch
getSources()
getTransformations()
cps <- VCorpus(VectorSource(lunch))
cps
tdm <- TermDocumentMatrix(cps)
tdm
as.matrix(tdm)
(m <- as.matrix(tdm))
tdm <- TermDocumentMatrix(cps)
(m <- as.matrix(tdm))
tdm <- TermDocumentMatrix(cps, control=list(wordLengths = c(1, Inf)))
tdm
inspect(tdm)
(m <- as.matrix(tdm))
rowSums(m)
colSums(m)
names(sort(rowSums(m), decreasing=T)[1])
sort(rowSums(m), decreasing=T)[1]
m
t(m)
# Co-occurrence matrix - 동시 발생 행렬 -
# 6명이 각각 먹은 점심 메뉴에서 함께 먹은 메뉴 즉 함께 선택되는 메뉴들을 알 수 있다.
menucom <- m %*% t(m)
memucom
# Co-occurrence matrix - 동시 발생 행렬 -
# 6명이 각각 먹은 점심 메뉴에서 함께 먹은 메뉴 즉 함께 선택되는 메뉴들을 알 수 있다.
menucom <- m %*% t(m)
memucom
menucom
View(menucom)
old <- par(family = "maple")
# 텍스트 분석 시각화 : 네트워크 그래프
qgraph(menucom, labels=rownames(com), diag=F,
layout='spring',  edge.color='blue', color=rainbow(7),
vsize=log(diag(com)*10000), title="함께 선택한 메뉴들", title.cex=2.5, title.color='red')
# 텍스트 분석 시각화 : 네트워크 그래프
qgraph(menucom, labels=rownames(menucom), diag=F,
layout='spring',  edge.color='blue', color=rainbow(7),
vsize=log(diag(com)*10000), title="함께 선택한 메뉴들", title.cex=2.5, title.color='red')
# 텍스트 분석 시각화 : 네트워크 그래프
qgraph(menucom, labels=rownames(menucom), diag=F,
layout='spring',  edge.color='blue', color=rainbow(7),
vsize=log(diag(com)*10000), title="함께 선택한 메뉴들", title.cex=2.5, title.color='red')
# 텍스트 분석 시각화 : 네트워크 그래프
qgraph(menucom, labels=rownames(menucom), diag=F,
layout='spring',  edge.color='blue', color=rainbow(7),
vsize=log(diag(menucom)*10000), title="함께 선택한 메뉴들", title.cex=2.5, title.color='red')
# 텍스트 분석 시각화 : 네트워크 그래프
qgraph(menucom, labels=rownames(menucom), diag=F,
layout='spring',  edge.color='blue', color=rainbow(10),
vsize=log(diag(menucom)*10000), title="함께 선택한 메뉴들", title.cex=2.5, title.color='red')
# 텍스트 분석 시각화 : 네트워크 그래프
qgraph(menucom, labels=rownames(menucom), diag=F,
layout='spring',  edge.color='blue', color=rainbow(3),
vsize=log(diag(menucom)*10000), title="함께 선택한 메뉴들", title.cex=2.5, title.color='red')
7
# 텍스트 분석 시각화 : 네트워크 그래프
qgraph(menucom, labels=rownames(menucom), diag=F,
layout='spring',  edge.color='blue', color=rainbow(7),
vsize=log(diag(menucom)*10000), title="함께 선택한 메뉴들", title.cex=2.5, title.color='red')
qgraph(menucom, labels=rownames(menucom), diag=F, shape='square',
layout='spring',  edge.color='blue', color=topo.colors(7),
vsize=log(diag(menucom)*10000), title="함께 선택한 메뉴들", title.cex=2.5, title.color='red')
qgraph(menucom, labels=rownames(menucom), diag=F, shape='diamond',
layout='spring',  edge.color='blue', color='green',
vsize=log(diag(menucom)*10000), title="함께 선택한 메뉴들", title.cex=2.5, title.color='red')
qgraph(menucom, labels=rownames(menucom), diag=F, shape='square',
layout='spring',  edge.color='blue', color=topo.colors(7),
vsize=log(diag(menucom)*10000), title="함께 선택한 메뉴들", title.cex=2.5, title.color='red')
# 텍스트 분석 시각화 : 네트워크 그래프
qgraph(menucom, labels=rownames(menucom), diag=F,
layout='spring',  edge.color='blue', color=rainbow(7),
vsize=log(diag(menucom)*10000), title="함께 선택한 메뉴들", title.cex=2.5, title.color='red')
qgraph(menucom, labels=rownames(menucom), diag=F, shape='square',
layout='spring',  edge.color='blue', color=topo.colors(7),
vsize=log(diag(menucom)*10000), title="함께 선택한 메뉴들", title.cex=2.5, title.color='red')
qgraph(menucom, labels=rownames(menucom), diag=F, shape='square',
layout='spring',  edge.color='blue', color=topo.colors(7),
vsize=log(diag(menucom)*10000), title="함께 선택한 메뉴들", title.cex=2.5, label.color='red')
qgraph(menucom, labels=rownames(menucom), diag=F, shape='square',
layout='spring',  edge.color='blue', color=topo.colors(7),
vsize=log(diag(menucom)*10000), title="함께 선택한 메뉴들", title.cex=2.5, .color='red')
qgraph(menucom, labels=rownames(menucom), diag=F, shape='square',
layout='spring',  edge.color='blue', color=topo.colors(7),
vsize=log(diag(menucom)*10000), title="함께 선택한 메뉴들", title.cex=2.5, color='red')
title
qgraph(menucom, labels=rownames(menucom), diag=F, shape='square',
layout='spring',  edge.color='blue', color=topo.colors(7),
vsize=log(diag(menucom)*10000), title="함께 선택한 메뉴들", title.cex=2.5, title.color='red')
# Document Term Matrix
dtm <- DocumentTermMatrix(cps, control=list(wordLengths = c(1, Inf)))
dtm
(m <- as.matrix(dtm))
(m <- as.matrix(dtm))
partnercom <- m %*% t(m)
partnercom
# 유사도 거리(코사인, 유클리디언)
dist(partnercom, method = "cosine")
dist(partnercom, method = "Euclidean")
# 문서(문장)의 유사도 분석을 간단하게 알아보자
dd <- NULL
d1 <- c("aaa bbb ccc")
d2 <- c("aaa bbb ddd")
d3 <- c("aaa bbb ccc")
d4 <- c("xxx yyy zzz")
dd <- c(d1, d2, d3, d4)
cps <- VCorpus(VectorSource(dd))
dtm <- DocumentTermMatrix(cps)
as.matrix(dtm)
m <- as.matrix(dtm)
doccom <- m %*% t(m)
doccom
# 거리로 구하는 함수
dist(doccom, method = "cosine")
dist(doccom, method = "Euclidean")
# 유사성으로 구하는 함수
simil(doccom, method = "cosine")
simil(doccom, method = "Euclidean")
A <- c('포도 바나나 딸기 맥주 비빔밥 여행 낚시 떡볶이 분홍색 듀크 귤 딸기')
B <- c('사과 와인 스테이크 배 포도 여행 등산 짜장면 냉면 삼겹살 파란색 듀크 귤 귤')
C <- c('백숙 바나나 맥주 여행 피자 콜라 햄버거 비빔밥 파란색 듀크 귤 귤')
D <- c('귤 와인 스테이크 배 포도 햄버거 등산 갈비 냉면 삼겹살 녹색 듀크')
data <- c(A,B,C,D)
cps <- VCorpus(VectorSource(data))
tdm <- TermDocumentMatrix(cps, control=list(wordLengths = c(1, Inf)))
inspect(tdm)
(m <- as.matrix(tdm))
(v <- sort(rowSums(m), decreasing=T))
m1 <- as.matrix(weightTf(tdm))
m2 <- as.matrix(weightTfIdf(tdm))
m1;m2
library(KoNLP)
useSejongDic()
library(jsonlite)
library(httr)
library(tm)
library(qgraph)
searchUrl<- "https://openapi.naver.com/v1/search/blog.json"
Client_ID <- "izGsqP2exeThwwEUVU3x"
Client_Secret <- "WrwbQ1l6ZI"
query <- URLencode("봄") ;
url <- paste0(searchUrl, "?query=", query, "&display=100")
response <- GET(url, add_headers("Content_Type" = "application/json",
"X-Naver-client-Id" = Client_ID, "X-naver-Client-Secret" = Client_Secret))
json_data <- httr::content(response, type='text', encoding="UTF-8")
json_obj <- fromJSON(json_data)
df <- data.frame(json_obj)
head(df)
blogtext <- df$items.description
blogtext
blogtext <- gsub("</?b>", "", blogtext)
blogtext <- gsub("&.+;", "", blogtext)
blogtext <- gsub("[[:digit:][:punct:][:lower:][:upper:]]", "", blogtext)
blogtext <- gsub("\\s{2,}", " ", blogtext)
blogtext
extractednoun <- extractNoun(blogtext)
extractednoun[[100]]
keyword <- sapply(extractednoun, function(d) paste(d, collapse = " "))
keyword[[100]]
corpus <- VCorpus(VectorSource(keyword))
stopWord <- c("텍스트", "분석")
tdm <- TermDocumentMatrix(corpus, control=list(stopwords=stopWord, wordLengths=c(2, Inf)))
(tdm.matrix <- as.matrix(tdm))
word.count <- rowSums(tdm.matrix)
word.order <- order(word.count, decreasing=TRUE)
freq.words <- tdm.matrix[word.order[1:30], ]
freq.words
co.matrix <- freq.words %*% t(freq.words)
old <- par(family = "maple")
qgraph(co.matrix, labels=rownames(co.matrix),
diag=FALSE, layout='spring', threshold=1,
vsize=log(diag(co.matrix)) * 3)
par(old)
par(family = "dog")
par(old)
qgraph(co.matrix, labels=rownames(co.matrix),
diag=FALSE, layout='spring', threshold=1,
vsize=log(diag(co.matrix)) * 3)
par(old)
old <- par(family = "maple")
qgraph(co.matrix, labels=rownames(co.matrix),
diag=FALSE, layout='spring', threshold=1,
vsize=log(diag(co.matrix)) * 3)
par(old)
library(rvest)
library(XML)
html.parsed <- htmlParse("data/TextofSteveJobs.html")
text <- xpathSApply(html.parsed, path="//p", xmlValue)
text
text <- text[4:30]
text
docs <- VCorpus(VectorSource(text))
docs
toSpace <- content_transformer(function(x, pattern){return(gsub(pattern, " ", x))})
docs <- tm_map(docs, toSpace, ":")
docs <- tm_map(docs, toSpace, ";")
docs <- tm_map(docs, toSpace, "'")
docs
docs[[17]]
docs[[19]]
docs[[17]]$content
docs[[19]]$content
docs[[17]]
text[17]
docs <- tm_map(docs, removePunctuation)
text[17]
docs[[17]]$content
docs <- tm_map(docs, content_transformer(tolower))
docs[[17]]$content
docs <- tm_map(docs, removeNumbers)
docs[[17]]$content
docs <- tm_map(docs, removeWords, stopwords("english"))
docs[[17]]$content
getTransformations()
tdm1 <- TermDocumentMatrix(docs, control=List(wordLengths = c(1, Inf)))
mystopwords <- readLines("data/stopwords_ko.txt", encoding="UTF-8")
text <- readLines("data/stopwords_testdata.txt", encoding="UTF-8")
docs <- VCorpus(VectorSource(text))
inspect(docs)
docs <- tm_map(docs, removeNumbers)
inspect(docs)
docs <- tm_map(docs, removePunctuation)
inspect(docs)
docs <- tm_map(docs, removeWords, mystopwords)
inspect(docs)
tdm1 <- TermDocumentMatrix(docs, control=List(wordLengths = c(1, Inf)))
tdm1 <- TermDocumentMatrix(docs, control=list(wordLengths = c(1, Inf)))
as.matrix(tmd)
tdm <- TermDocumentMatrix(docs, control=list(wordLengths = c(1, Inf)))
as.matrix(tmd)
tdm <- TermDocumentMatrix(docs, control=list(wordLengths = c(1, Inf)))
as.matrix(tmd)
as.matrix(tdm)
docs2 <- VCorpus(VectorSource(text))
tdm1 <- TermDocumentMatrix(docs2, control=list(wordLengths = c(1, Inf)))
as.matrix(tdm1)
tdm2 <- TermDocumentMatrix(docs2, control=list(
removePunctuation = T,
removeNumbers = T,
wordLengths = c(1, Inf),
stopwords=mystopwords))
as.matrix(tdm2)
stopwords::stopwords()
# 한국어 불용어
# https://www.rdocumentation.org/packages/stopwords/versions/2.2
library(stopwords)
library(stopwords)
library(tm)
library(stopwords)
# 한국어 불용어
# https://www.rdocumentation.org/packages/stopwords/versions/2.2
install.packages("stopwords")
library(stopwords)
stopwords::stopwords()
stopwords_getsources()
tm
tm()
st <- head(stopwords::stopwords("ko", source = "marimo"), 100)
dd <- c("저는 유니코입니다", "우리 모두 건강하게 보내요")
st
docs <- VCorpus(VectorSource(dd))
docs
r <- tm_map(docs,removeWords,st)
str(r)
r$dmeta
r[[1]]$content
r[[2]]$content
# 문제1
grade <- read.csv("data/성적2.csv")
View(grade)
boxplot(grade)
boxplot(grade$성명)
boxplot(grade$국어)
boxplot(dist, main='자동차 제동거리')
boxplot.stats(dist)
boxplot(Petal.Length~Species,            # 자료와 그룹 정보
data=iris,                       # 자료가 저장된 자료구조
main='품종별 꽃잎의 길이',       # 그래프의 제목
col=c('green','yellow','blue'))  # 상자들의 색
boxplot(dist, main='자동차 제동거리')
boxplot.stats(dist)
boxplot(Petal.Length~Species,            # 자료와 그룹 정보
data=iris,                       # 자료가 저장된 자료구조
main='품종별 꽃잎의 길이',       # 그래프의 제목
col=c('green','yellow','blue'))  # 상자들의 색
iris
gap_wide <- read.csv("data/gapminder_wide.csv", stringsAsFactors = FALSE)
str(gap_wide)
View(gap_wide)
gap_long1 <- gap_wide %>%
gather(obstype_year, obs_values, starts_with('pop'),
starts_with('lifeExp'), starts_with('gdpPercap'))
library(tidyr)
library(dplyr)
gap_long1 <- gap_wide %>%
gather(obstype_year, obs_values, starts_with('pop'),
starts_with('lifeExp'), starts_with('gdpPercap'))
View(gap_long1)
View(gap_wide)
gap_long2 <- gap_wide %>% gather(obstype_year,obs_values,-continent,-country)
str(gap_long2)
View(gap_long2)
gap_long3 <- gap_long1 %>% separate(obstype_year,into=c('obs_type','year'),sep="_")
gap_long3$year <- as.integer(gap_long3$year)
str(gap_long3)
View(gap_long3)
gap_long3 %>% group_by(continent,obs_type) %>%
summarize(means=mean(obs_values))
View(mtcars)
mtcars$name = rownames(mtcars)
rownames(mtcars) = NULL
View(mtcars)
my_data2 <- gather(my_data,
key = "arrest_attribute",
value = "arrest_estimate",
-state)
my_data2
my_data
boxplot(grade$국어)
boxplot(grade$국어~수학)
boxplot(grade$국어, 수학)
boxplot(grade$국어, grade$수학)
# 이상치 포함된 데이터 생성 - sex 3, score 6
outlier <- data.frame(sex = c(1, 2, 1, 3, 2, 1),  score = c(5, 4, 3, 4, 2, 6))
# 이상치 확인하기
table(outlier$sex)
table(outlier$score)
grade$수학 <- ifelse(grade$수학 > 3, NA, grade$수학)
View(grade)
# 문제1
grade <- read.csv("data/성적2.csv")
View(grade)
grade$수학 <- ifelse(grade$수학 > 10, NA, grade$수학)
View(grade)
boxplot(grade$국어, grade$수학)
# 문제1
grade <- read.csv("data/성적2.csv")
View(grade)
# 결측치 제외하고 분석
outlier %>%
filter(!is.na(sex) & !is.na(score)) %>%
group_by(sex) %>%
summarise(mean_score = mean(score))
mpg <- as.data.frame(ggplot2::mpg)
View(mpg)
boxplot(mpg$hwy, notch=T) # , notch=T
boxplot(mpg$hwy, range=0)
summary(mpg$hwy)
# 결측 처리하기
# 12~37 벗어나면 NA 할당
mpg$hwy <- ifelse(mpg$hwy < 12 | mpg$hwy > 37, NA, mpg$hwy)
table(is.na(mpg$hwy))
# 결측치 제외하고 분석하기
mpg %>%
group_by(drv) %>%
summarise(mean_hwy = mean(hwy, na.rm = T))
# 결측치 제외하고 분석
outlier %>%
filter(!is.na(sex) & !is.na(score)) %>%
group_by(sex) %>%
summarise(mean_score = mean(score))
mpg <- as.data.frame(ggplot2::mpg)
View(mpg)
# grade$수학 <- ifelse(grade$수학 > 10, NA, grade$수학)
boxplot(grade$국어, grade$수학)
# grade$수학 <- ifelse(grade$수학 > 10, NA, grade$수학)
boxplot(grade$국어, grade$수학, range=1)
# grade$수학 <- ifelse(grade$수학 > 10, NA, grade$수학)
boxplot(grade$국어, grade$수학, name=c("국어","수학"),range=1)
# grade$수학 <- ifelse(grade$수학 > 10, NA, grade$수학)
boxplot(grade$국어, grade$수학, name=c("kor","math"),range=1)
# grade$수학 <- ifelse(grade$수학 > 10, NA, grade$수학)
boxplot(grade$국어, grade$수학, name=c("kor","math"),range=1)
# grade$수학 <- ifelse(grade$수학 > 10, NA, grade$수학)
boxplot(grade$국어, grade$수학, range=1)
# 문제1
grade <- read.csv("data/성적2.csv")
# grade$수학 <- ifelse(grade$수학 > 10, NA, grade$수학)
boxplot(grade$국어, grade$수학, range=1)
# 그림3
grade$수학 <- ifelse(grade$수학 > 10, mean(grade$수학), grade$수학)
# 그림1
View(grade)
# 문제1
grade <- read.csv("data/성적2.csv")
# 그림1
View(grade)
#
# 그림2
boxplot(grade$국어, grade$수학, range=1)
# 그림3
grade$수학 <- ifelse(grade$수학 > 10, mean(grade$수학), grade$수학)
source("~/pjh/Rexam/lab18.R", echo=TRUE)
grade$수학
mean(grade$수학)
min(grade$수학)
mean(수학)
# 그림4
grade %>% group_by(국어, 수학)
# 그림4
grade %>% fill(국어, .diection="updown")
# 그림4
grade %>% group_by(성명) %>% fill(국어, .diection="updown")
fill(국어, .diection="updown")
boxplot(grade$국어, grade$수학, range=1)$stat
boxplot(grade$국어, grade$수학, range=1)
# 그림2
png("output/result1-2.png", width=960, height=540)
boxplot(grade$국어, grade$수학, range=1)$stat # boxplot(grande[,c(3:4)], range=1)
boxplot(grade$국어, grade$수학, range=1)
# 문제1
grade <- read.csv("data/성적2.csv")
# 그림1
View(grade)
# 문제1
grade <- read.csv("data/성적2.csv")
# 그림1
View(grade)
# 문제1
grade <- read.csv("data/성적2.csv")
# 그림4
grade %>% fill(국어, .direction="updown") %>% fill(수학, .direction="updown")
# 문제1
grade <- read.csv("data/성적2.csv")
# 그림1
View(grade)
# 그림3
grade$수학 <- ifelse(grade$수학 > 10, mean(grade$수학), grade$수학)
View(grade)
# 그림4
grade %>% fill(국어, .direction="updown") %>% fill(수학, .direction="updown")
