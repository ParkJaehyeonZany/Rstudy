v1 <- 1:10
v1*10
LETTERS
print(LETTERS)
V1 > 5
V1>5
V1 > 5
v1 > 5
# 문제1
movie <- read.csv("output/movie_reviews3.csv")
library(KoNLP)
# 일부 패키지의 버전 문제로 업데이트 설치 요구함. 1번 선택하고 계속 진행할 것
useSejongDic()
library(wordcloud)
library(wordcloud2)
library(htmlwidgets)
# 네이버 블로그 글 워드클라우드
library(XML)
library(httr)
# 문제1
movie <- read.csv("output/movie_reviews3.csv")
getwd() # get working directory, (참고) 경로 설정 : setwd('c:/pjh/Rexam/')
setwd('c:/pjh/Rexam/')
# 문제1
movie <- read.csv("output/movie_reviews3.csv")
movie_gsub <- gsub("[[:punct:]][A-Za-z0-9ㄱ-ㅎㅏ-ㅣ]","", movie)
extractNoun(movie_gsub)
movie
movie_gsub
movie_gsub <- gsub("[[:punct:]][A-Za-z0-9ㄱ-ㅎㅏ-ㅣ][(\n)\]","", movie)
table(movie_dn)
movie_dn <- extractNoun(movie_gsub)
table(movie_dn)
movie_dn
table(movie_dn[4])
table(unlist(movie_dn[4]))
movie_table<- table(unlist(movie_dn[4]))
movie_table
movie_data <- Filter(function(x) {nachar(x) >= 2}, movie_table)
movie_data <- Filter(function(x) {nchar(x) >= 2}, movie_table)
movie_data
add_words <- c("백두산", "남산", "철갑", "가을", "달")
buildDictionary(user_dic=data.frame(add_words, rep("ncn")), replace_usr_dic=T)
word_data3 <- extractNoun(word_data)
word_data3
word_data <- readLines("data/애국가(가사).txt")
word_data
word_data2 <- sapply(word_data, extractNoun, USE.NAMES = F)
word_data2
word_data3 <- extractNoun(word_data)
word_data3
add_words <- c("백두산", "남산", "철갑", "가을", "달")
buildDictionary(user_dic=data.frame(add_words, rep("ncn")), replace_usr_dic=T)
word_data3 <- extractNoun(word_data)
word_data3
undata <- unlist(word_data3)
undata
word_table <- table(undata)
word_table
undata2 <- Filter(function(x) {nchar(x) >= 2}, undata)
word_table2 <- table(undata2)
word_table2
final <- sort(word_table2, decreasing = T)
head(final, 10)
extractNoun("대한민국의 영토는 한반도와 그 부속도서로 한다")
SimplePos09("대한민국의 영토는 한반도와 그 부속도서로 한다")
SimplePos22("대한민국의 영토는 한반도와 그 부속도서로 한다")
# 문제2
book <- readline("output/yes24.txt")
# 문제2
book <- readLines("output/yes24.txt")
book
unlist(book)
# 블로그 내용에 대한 리스트 만들기
doc2 <- xmlParse(doc, encoding="UTF-8")
# 네이버 블로그 글 워드클라우드
library(XML)
library(httr)
searchUrl<- "https://openapi.naver.com/v1/search/blog.xml"
Client_ID <- "izGsqP2exeThwwEUVU3x"
Client_Secret <- "WrwbQ1l6ZI"
query <- URLencode("봄")
url <- paste0(searchUrl, "?query=", query, "&display=100")
doc <- GET(url, add_headers("Content_Type" = "application/xml",
"X-Naver-client-Id" = Client_ID, "X-naver-Client-Secret" = Client_Secret))
# 블로그 내용에 대한 리스트 만들기
doc2 <- xmlParse(doc, encoding="UTF-8")
spring <- xpathSApply(doc2, "//item/description", xmlValue)
spring <- gsub("</?b>", "", spring)
spring <- gsub("&[a-z];", "", spring)
spring
(words <- read.csv("data/wc.csv"))
movie
movie_gsub
book
extractNoun(book)
book_n <- extractNoun(book)
gsub("[^가-힣]", "", book_n)
gsub("[^가-힣 ]", "", book_n)
gsub("[^가-힣]", "", book_n)
book_gusb <- gsub("[^가-힣] ", "", book_n)
undata <- Filter(function(x) {nchar(x) >= 2 & nchar(x) <= 4}, book_gusb)
undata
length(undata)
sort(undata)
table(undata)
